{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1bc3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4215321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tmdbsimple in c:\\users\\jhugh\\anaconda3\\envs\\dojo-env\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\jhugh\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from tmdbsimple) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jhugh\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jhugh\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\jhugh\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jhugh\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tmdbsimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33164f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tmbd_key'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('/Users/jhugh/.secret/tmdb_api.json','r') as f:\n",
    "    login= json.load(f)\n",
    "    \n",
    "login.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75143159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmdbsimple as tmdb\n",
    "tmdb.API_KEY = login['tmbd_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "309aebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7b224de",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = tmdb.Movies(603)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca94811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': '/l4QHerTSbMI7qgvasqxP36pqjN6.jpg',\n",
       " 'belongs_to_collection': {'id': 2344,\n",
       "  'name': 'The Matrix Collection',\n",
       "  'poster_path': '/bV9qTVHTVf0gkW0j7p7M0ILD4pG.jpg',\n",
       "  'backdrop_path': '/bRm2DEgUiYciDw3myHuYFInD7la.jpg'},\n",
       " 'budget': 63000000,\n",
       " 'genres': [{'id': 28, 'name': 'Action'},\n",
       "  {'id': 878, 'name': 'Science Fiction'}],\n",
       " 'homepage': 'http://www.warnerbros.com/matrix',\n",
       " 'id': 603,\n",
       " 'imdb_id': 'tt0133093',\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'The Matrix',\n",
       " 'overview': 'Set in the 22nd century, The Matrix tells the story of a computer hacker who joins a group of underground insurgents fighting the vast and powerful computers who now rule the earth.',\n",
       " 'popularity': 64.287,\n",
       " 'poster_path': '/f89U3ADr1oiB1s9GkdPOEpXUk5H.jpg',\n",
       " 'production_companies': [{'id': 79,\n",
       "   'logo_path': '/tpFpsqbleCzEE2p5EgvUq6ozfCA.png',\n",
       "   'name': 'Village Roadshow Pictures',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 174,\n",
       "   'logo_path': '/IuAlhI9eVC9Z8UQWOIDdWRKSEJ.png',\n",
       "   'name': 'Warner Bros. Pictures',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 372,\n",
       "   'logo_path': None,\n",
       "   'name': 'Groucho II Film Partnership',\n",
       "   'origin_country': ''},\n",
       "  {'id': 1885,\n",
       "   'logo_path': '/tXMFoE8AtNdnFzWOW0aCLwl7xxS.png',\n",
       "   'name': 'Silver Pictures',\n",
       "   'origin_country': 'US'}],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '1999-03-30',\n",
       " 'revenue': 463517383,\n",
       " 'runtime': 136,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': 'Welcome to the Real World.',\n",
       " 'title': 'The Matrix',\n",
       " 'video': False,\n",
       " 'vote_average': 8.192,\n",
       " 'vote_count': 22229}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = movie.info()\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f84d0aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77caf960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463517383"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65ead885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tt0133093'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['imdb_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3281bf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = tmdb.Movies('tt1361336')\n",
    "info = movie.info()\n",
    "info['budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f228e193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PG\n",
      "PG\n",
      "PG\n"
     ]
    }
   ],
   "source": [
    "# example from package README\n",
    "# source = https://github.com/celiao/tmdbsimple\n",
    "response = movie.releases()\n",
    "for c in movie.countries:\n",
    "    if c['iso_3166_1'] == 'US':\n",
    "        print(c['certification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53449153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the movie object for the current id\n",
    "movie = tmdb.Movies('tt1361336')\n",
    "# save the .info .releases dictionaries\n",
    "info = movie.info()\n",
    "releases = movie.releases()\n",
    "# Loop through countries in releases\n",
    "for c in releases['countries']:\n",
    "    # if the country abbreviation==US\n",
    "    if c['iso_3166_1' ] =='US':\n",
    "        ## save a \"certification\" key in the info dict with the certification\n",
    "       info['certification'] = c['certification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "815e3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_rating(movie_id):\n",
    "    \"\"\"Adapted from source = https://github.com/celiao/tmdbsimple\"\"\"\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    info = movie.info()\n",
    "    releases = movie.releases()\n",
    "    #Loop through countries in releases\n",
    "    for c in releases['countries']:\n",
    "        if c['iso_3166_1']=='US':\n",
    "            info['certificiation']=c['certification']\n",
    "            return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b6cca32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': '/9BBTo63ANSmhC4e6r62OJFuK2GL.jpg',\n",
       " 'belongs_to_collection': {'id': 86311,\n",
       "  'name': 'The Avengers Collection',\n",
       "  'poster_path': '/yFSIUVTCvgYrpalUktulvk3Gi5Y.jpg',\n",
       "  'backdrop_path': '/zuW6fOiusv4X9nnW3paHGfXcSll.jpg'},\n",
       " 'budget': 220000000,\n",
       " 'genres': [{'id': 878, 'name': 'Science Fiction'},\n",
       "  {'id': 28, 'name': 'Action'},\n",
       "  {'id': 12, 'name': 'Adventure'}],\n",
       " 'homepage': 'https://www.marvel.com/movies/the-avengers',\n",
       " 'id': 24428,\n",
       " 'imdb_id': 'tt0848228',\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'The Avengers',\n",
       " 'overview': 'When an unexpected enemy emerges and threatens global safety and security, Nick Fury, director of the international peacekeeping agency known as S.H.I.E.L.D., finds himself in need of a team to pull the world back from the brink of disaster. Spanning the globe, a daring recruitment effort begins!',\n",
       " 'popularity': 218.398,\n",
       " 'poster_path': '/RYMX2wcKCBAr24UyPD7xwmjaTn.jpg',\n",
       " 'production_companies': [{'id': 420,\n",
       "   'logo_path': '/hUzeosd33nzE5MCNsZxCGEKTXaQ.png',\n",
       "   'name': 'Marvel Studios',\n",
       "   'origin_country': 'US'}],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '2012-04-25',\n",
       " 'revenue': 1518815515,\n",
       " 'runtime': 143,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'},\n",
       "  {'english_name': 'Hindi', 'iso_639_1': 'hi', 'name': 'हिन्दी'},\n",
       "  {'english_name': 'Russian', 'iso_639_1': 'ru', 'name': 'Pусский'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': 'Some assembly required.',\n",
       " 'title': 'The Avengers',\n",
       " 'video': False,\n",
       " 'vote_average': 7.706,\n",
       " 'vote_count': 27647,\n",
       " 'certificiation': 'PG-13'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = get_movie_with_rating(\"tt0848228\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fd31ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': '/qom1SZSENdmHFNZBXbtJAU0WTlC.jpg',\n",
       " 'belongs_to_collection': None,\n",
       " 'budget': 29000000,\n",
       " 'genres': [{'id': 10749, 'name': 'Romance'}, {'id': 18, 'name': 'Drama'}],\n",
       " 'homepage': 'http://www.newline.com/properties/notebookthe.html',\n",
       " 'id': 11036,\n",
       " 'imdb_id': 'tt0332280',\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'The Notebook',\n",
       " 'overview': \"An epic love story centered around an older man who reads aloud to a woman with Alzheimer's. From a faded notebook, the old man's words bring to life the story about a couple who is separated by World War II, and is then passionately reunited, seven years later, after they have taken different paths.\",\n",
       " 'popularity': 59.791,\n",
       " 'poster_path': '/rNzQyW4f8B8cQeg7Dgj3n6eT5k9.jpg',\n",
       " 'production_companies': [{'id': 12,\n",
       "   'logo_path': '/iaYpEp3LQmb8AfAtmTvpqd4149c.png',\n",
       "   'name': 'New Line Cinema',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 1565, 'logo_path': None, 'name': 'Avery Pix', 'origin_country': 'US'},\n",
       "  {'id': 2605,\n",
       "   'logo_path': None,\n",
       "   'name': 'Gran Via Productions',\n",
       "   'origin_country': 'US'}],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '2004-06-25',\n",
       " 'revenue': 115603229,\n",
       " 'runtime': 123,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': 'Behind every great love is a great story.',\n",
       " 'title': 'The Notebook',\n",
       " 'video': False,\n",
       " 'vote_average': 7.88,\n",
       " 'vote_count': 9867,\n",
       " 'certificiation': 'PG-13'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = get_movie_with_rating(\"tt0332280\")\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2efa0fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'title_akas.csv.gz',\n",
       " 'title_basics.csv.gz',\n",
       " 'title_ratings.csv.gz',\n",
       " 'tmdb_api_results_2000.json']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, time, json\n",
    "import tmdbsimple as tmdb\n",
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66dcd26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS_TO_GET = [2000,2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d19ecc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0035423</td>\n",
       "      <td>movie</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>Comedy,Fantasy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0062336</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Tango of the Widower and Its Distorting Mi...</td>\n",
       "      <td>El Tango del Viudo y Su Espejo Deformante</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0069049</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0079644</td>\n",
       "      <td>movie</td>\n",
       "      <td>November 1828</td>\n",
       "      <td>November 1828</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>Drama,War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0088751</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>Comedy,Horror,Sci-Fi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst titleType                                       primaryTitle  \\\n",
       "0  tt0035423     movie                                     Kate & Leopold   \n",
       "1  tt0062336     movie  The Tango of the Widower and Its Distorting Mi...   \n",
       "2  tt0069049     movie                         The Other Side of the Wind   \n",
       "3  tt0079644     movie                                      November 1828   \n",
       "4  tt0088751     movie                                  The Naked Monster   \n",
       "\n",
       "                               originalTitle  isAdult  startYear  endYear  \\\n",
       "0                             Kate & Leopold        0     2001.0      NaN   \n",
       "1  El Tango del Viudo y Su Espejo Deformante        0     2020.0      NaN   \n",
       "2                 The Other Side of the Wind        0     2018.0      NaN   \n",
       "3                              November 1828        0     2001.0      NaN   \n",
       "4                          The Naked Monster        0     2005.0      NaN   \n",
       "\n",
       "   runtimeMinutes                  genres  \n",
       "0             118  Comedy,Fantasy,Romance  \n",
       "1              70                   Drama  \n",
       "2             122                   Drama  \n",
       "3             140               Drama,War  \n",
       "4             100    Comedy,Horror,Sci-Fi  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basics = pd.read_csv('Data/title_basics.csv.gz')\n",
    "\n",
    "basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e79bb7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e43409b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dac0052c4f4e67802eff53676bd79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YEARS:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m movie_ids \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtconst\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Load existing data from json into a dataframe called \"previous_df\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Instead of previous_df=pd.read_json:\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m previous_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(JSON_FILE)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# filter out any ids that are already in the JSON_FILE\u001b[39;00m\n\u001b[0;32m     29\u001b[0m movie_ids_to_get \u001b[38;5;241m=\u001b[39m movie_ids[\u001b[38;5;241m~\u001b[39mmovie_ids\u001b[38;5;241m.\u001b[39misin(previous_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdb_id\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:207\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:612\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m json_reader:\n\u001b[1;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:746\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    744\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_lines(data_lines))\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:768\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    766\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 768\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:880\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_numpy()\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 880\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_no_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:1132\u001b[0m, in \u001b[0;36mFrameParser._parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1129\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1136\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1139\u001b[0m     }\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\frame.py:721\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;66;03m# error: Argument 1 to \"ensure_index\" has incompatible type\u001b[39;00m\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;66;03m# \"Collection[Any]\"; expected \"Union[Union[Union[ExtensionArray,\u001b[39;00m\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;66;03m# ndarray], Index, Series], Sequence[Any]]\"\u001b[39;00m\n\u001b[0;32m    720\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    729\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    730\u001b[0m         arrays,\n\u001b[0;32m    731\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    734\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    735\u001b[0m     )\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:519\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 519\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:875\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    873\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m0\u001b[39m], abc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m--> 875\u001b[0m     arr, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_list_of_dict_to_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m    877\u001b[0m     arr, columns \u001b[38;5;241m=\u001b[39m _list_of_series_to_arrays(data, columns)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:960\u001b[0m, in \u001b[0;36m_list_of_dict_to_arrays\u001b[1;34m(data, columns)\u001b[0m\n\u001b[0;32m    958\u001b[0m     gen \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m(x\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[0;32m    959\u001b[0m     sort \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(d, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[1;32m--> 960\u001b[0m     pre_cols \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_unique_multiple_list_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    961\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(pre_cols)\n\u001b[0;32m    963\u001b[0m \u001b[38;5;66;03m# assure that they are of the base dict class and not of derived\u001b[39;00m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;66;03m# classes\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\_libs\\lib.pyx:403\u001b[0m, in \u001b[0;36mpandas._libs.lib.fast_unique_multiple_list_gen\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:958\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;124;03mConvert list of dicts to numpy arrays\u001b[39;00m\n\u001b[0;32m    940\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;124;03mcolumns : Index\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 958\u001b[0m     gen \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m()) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[0;32m    959\u001b[0m     sort \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(d, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[0;32m    960\u001b[0m     pre_cols \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_unique_multiple_list_gen(gen, sort\u001b[38;5;241m=\u001b[39msort)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# Start of OUTER loop\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\n",
    "\n",
    "    #Defining the JSON file to store results for year\n",
    "    JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "\n",
    "    # Check if file exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "\n",
    "    # If it does not exist: create it\n",
    "    if file_exists == False:\n",
    "    # save an empty dict with just \"imdb_id\" to the new json file.\n",
    "        with open(JSON_FILE,'w') as f:\n",
    "            json.dump([{'imdb_id':0}],f)\n",
    "            \n",
    "\n",
    "    #Saving new year as the current df\n",
    "    df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "    # saving movie ids to list\n",
    "    movie_ids = df['tconst'].copy()\n",
    "\n",
    "    # Load existing data from json into a dataframe called \"previous_df\"\n",
    "    # Instead of previous_df=pd.read_json:\n",
    "    previous_df = pd.read_json(JSON_FILE)\n",
    "\n",
    "\n",
    "\n",
    "    # filter out any ids that are already in the JSON_FILE\n",
    "    movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "\n",
    "    #Get index and movie id from list\n",
    "    # INNER Loop\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                  desc=f'Movies from {YEAR}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "        try:\n",
    "            # Retrieve then data for the movie id\n",
    "            temp = get_movie_with_rating(movie_id)  \n",
    "            # Append/extend results to existing file using a pre-made function\n",
    "            write_json(temp,JSON_FILE)\n",
    "            # Short 20 ms sleep to prevent overwhelming server\n",
    "            time.sleep(0.02)\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "\n",
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
